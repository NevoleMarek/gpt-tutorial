{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input data\n",
    "with open(\"input.txt\") as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the dataset in characters 1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of the dataset in characters\", len(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First 1000 characters of the input data\n",
    "display(text[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# all unique characters in text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42, 2]\n",
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "# Create simple character tokenizer\n",
    "stoi = {c: i for i, c in enumerate(chars)}\n",
    "itos = {i: c for i, c in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \"\".join([itos[i] for i in l])\n",
    "print(encode(\"Hello world!\"))\n",
    "print(decode(encode(\"Hello world!\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "# Import torch and encode input data to tensor\n",
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long, device=None)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split encoded input into train and validation set\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "tensor([[57,  1, 46, 47, 57,  1, 50, 53],\n",
      "        [ 1, 58, 46, 43, 56, 43,  1, 41],\n",
      "        [17, 26, 15, 17, 10,  0, 32, 53],\n",
      "        [57, 58,  6,  1, 61, 47, 58, 46]])\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 1, 46, 47, 57,  1, 50, 53, 60],\n",
      "        [58, 46, 43, 56, 43,  1, 41, 39],\n",
      "        [26, 15, 17, 10,  0, 32, 53,  1],\n",
      "        [58,  6,  1, 61, 47, 58, 46,  0]])\n",
      "When input is [57] the target is: 1\n",
      "When input is [57, 1] the target is: 46\n",
      "When input is [57, 1, 46] the target is: 47\n",
      "When input is [57, 1, 46, 47] the target is: 57\n",
      "When input is [57, 1, 46, 47, 57] the target is: 1\n",
      "When input is [57, 1, 46, 47, 57, 1] the target is: 50\n",
      "When input is [57, 1, 46, 47, 57, 1, 50] the target is: 53\n",
      "When input is [57, 1, 46, 47, 57, 1, 50, 53] the target is: 60\n",
      "When input is [1] the target is: 58\n",
      "When input is [1, 58] the target is: 46\n",
      "When input is [1, 58, 46] the target is: 43\n",
      "When input is [1, 58, 46, 43] the target is: 56\n",
      "When input is [1, 58, 46, 43, 56] the target is: 43\n",
      "When input is [1, 58, 46, 43, 56, 43] the target is: 1\n",
      "When input is [1, 58, 46, 43, 56, 43, 1] the target is: 41\n",
      "When input is [1, 58, 46, 43, 56, 43, 1, 41] the target is: 39\n",
      "When input is [17] the target is: 26\n",
      "When input is [17, 26] the target is: 15\n",
      "When input is [17, 26, 15] the target is: 17\n",
      "When input is [17, 26, 15, 17] the target is: 10\n",
      "When input is [17, 26, 15, 17, 10] the target is: 0\n",
      "When input is [17, 26, 15, 17, 10, 0] the target is: 32\n",
      "When input is [17, 26, 15, 17, 10, 0, 32] the target is: 53\n",
      "When input is [17, 26, 15, 17, 10, 0, 32, 53] the target is: 1\n",
      "When input is [57] the target is: 58\n",
      "When input is [57, 58] the target is: 6\n",
      "When input is [57, 58, 6] the target is: 1\n",
      "When input is [57, 58, 6, 1] the target is: 61\n",
      "When input is [57, 58, 6, 1, 61] the target is: 47\n",
      "When input is [57, 58, 6, 1, 61, 47] the target is: 58\n",
      "When input is [57, 58, 6, 1, 61, 47, 58] the target is: 46\n",
      "When input is [57, 58, 6, 1, 61, 47, 58, 46] the target is: 0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "# Context visualization\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, : t + 1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"When input is {context.tolist()} the target is: {target}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8865, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "o$,q&IWqW&xtCjaB?ij&bYRGkF?b; f ,CbwhtERCIfuWr,DzJERjhLlVaF&EjffPHDFcNoGIG'&$qXisWTkJPw\n",
      " ,b Xgx?D3sj\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size) -> None:\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)  # (B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]  # (B, C)\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1995608806610107\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "\n",
    "for steps in range(2000):\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss =  m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate output from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "D,DJV!g: IwVzIs& Zus: VdircAse ker,heetigsmavwZisby\n",
      "abdyZGimgz$V,-\n",
      "criXvQFqn'deQyrolicQ!Az-IAn,pw,Dp\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mathematical trick in self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.rand(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1]\n",
    "        xbow[b,t] = torch.mean(xprev, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 3\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=1)\n",
    "xbow3 = wei @ x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self attention for one head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.6378e-01,  1.4320e-01,  1.0612e+00,  2.4182e-01, -3.6273e-01,\n",
       "           5.3863e-03, -7.1514e-01, -5.8126e-01, -3.9213e-01,  2.7544e-01,\n",
       "          -6.5308e-01, -3.8467e-01,  3.3778e-01, -5.4164e-01, -2.6631e-01,\n",
       "           4.0298e-01],\n",
       "         [ 1.4327e-01,  7.9573e-02,  1.0511e+00,  2.3275e-01, -2.7872e-01,\n",
       "          -5.7517e-02, -5.7715e-01, -6.2039e-01, -4.6231e-01,  2.9281e-01,\n",
       "          -8.4379e-01, -2.9442e-01,  4.0584e-01, -5.5960e-01, -1.9425e-01,\n",
       "           4.8614e-01],\n",
       "         [ 1.7828e-01,  4.6072e-02,  7.9989e-01,  1.3813e-01, -3.2865e-01,\n",
       "          -2.9892e-02, -3.8560e-01, -5.4209e-01, -4.2164e-01,  2.7821e-01,\n",
       "          -7.0592e-01, -3.4510e-01,  3.7394e-01, -4.5291e-01, -6.1384e-02,\n",
       "           4.5229e-01],\n",
       "         [ 1.5716e-01,  3.0422e-02,  6.9421e-01,  1.4530e-01, -2.8683e-01,\n",
       "          -2.3814e-02, -3.2727e-01, -4.4452e-01, -3.3291e-01,  2.4523e-01,\n",
       "          -6.7720e-01, -3.5894e-01,  3.4341e-01, -4.0172e-01, -6.1276e-02,\n",
       "           4.0395e-01],\n",
       "         [ 1.3382e-01,  1.3968e-02,  7.1551e-01,  1.7235e-01, -2.9461e-01,\n",
       "           8.0806e-02, -3.4257e-01, -4.0257e-01, -2.8659e-01,  2.7303e-01,\n",
       "          -6.1053e-01, -3.4942e-01,  3.7625e-01, -3.9172e-01, -3.6843e-02,\n",
       "           3.4859e-01],\n",
       "         [ 1.5264e-01,  3.1793e-02,  7.0322e-01,  2.1573e-01, -2.8280e-01,\n",
       "           5.9278e-02, -3.2157e-01, -3.9871e-01, -2.9916e-01,  2.8525e-01,\n",
       "          -5.9811e-01, -3.3814e-01,  3.4532e-01, -3.5184e-01,  3.2161e-02,\n",
       "           3.6581e-01],\n",
       "         [ 1.3290e-01,  4.7037e-03,  7.1816e-01,  2.4601e-01, -2.5023e-01,\n",
       "           5.3106e-02, -3.4733e-01, -3.6594e-01, -2.8433e-01,  2.8679e-01,\n",
       "          -5.6454e-01, -3.0492e-01,  3.3261e-01, -3.4062e-01,  4.7447e-02,\n",
       "           3.6964e-01],\n",
       "         [ 1.5657e-01,  2.0487e-02,  7.1494e-01,  2.3737e-01, -2.3732e-01,\n",
       "           2.0213e-02, -3.5762e-01, -3.8414e-01, -3.0167e-01,  2.6995e-01,\n",
       "          -5.0809e-01, -2.8784e-01,  3.2269e-01, -3.2106e-01,  7.9962e-03,\n",
       "           3.5025e-01]],\n",
       "\n",
       "        [[ 3.3697e-01, -2.2630e-01,  1.0337e+00, -5.8567e-02, -3.8306e-02,\n",
       "          -3.8480e-01, -8.0341e-02, -3.1042e-01, -3.0277e-01,  4.7227e-01,\n",
       "          -5.4734e-01, -2.9665e-01,  2.8592e-01, -1.2908e-01,  9.2965e-02,\n",
       "           3.4338e-01],\n",
       "         [ 3.0490e-01, -1.8507e-01,  7.0094e-01, -6.0408e-02, -1.3471e-01,\n",
       "          -2.2734e-01, -1.3444e-01, -2.9674e-01, -3.2654e-01,  4.5982e-01,\n",
       "          -5.3005e-01, -1.6077e-01,  3.0282e-01, -1.6836e-01,  1.3852e-01,\n",
       "           3.9698e-01],\n",
       "         [ 2.6391e-01, -1.0694e-01,  7.1743e-01,  3.3443e-04, -1.4336e-01,\n",
       "          -1.9513e-01, -1.9005e-01, -3.6186e-01, -3.2322e-01,  4.3729e-01,\n",
       "          -4.7310e-01, -2.0894e-01,  3.5546e-01, -2.3580e-01,  6.6771e-02,\n",
       "           2.8023e-01],\n",
       "         [ 2.9276e-01, -9.6732e-02,  7.5700e-01,  9.9305e-02, -1.9690e-01,\n",
       "          -1.1848e-01, -2.3284e-01, -4.0081e-01, -3.3650e-01,  4.0372e-01,\n",
       "          -5.2333e-01, -2.0209e-01,  4.2745e-01, -2.3525e-01,  2.5218e-02,\n",
       "           2.7866e-01],\n",
       "         [ 3.1979e-01, -3.1253e-02,  7.4959e-01,  1.2970e-01, -2.1749e-01,\n",
       "          -1.2218e-01, -2.4182e-01, -4.2665e-01, -3.0404e-01,  4.2251e-01,\n",
       "          -4.8620e-01, -2.0780e-01,  4.6172e-01, -2.3894e-01, -1.1591e-02,\n",
       "           2.8106e-01],\n",
       "         [ 3.3005e-01, -3.9273e-03,  7.2361e-01,  8.4838e-02, -2.5948e-01,\n",
       "          -1.4437e-01, -2.5536e-01, -4.8270e-01, -3.3622e-01,  4.2472e-01,\n",
       "          -5.2922e-01, -2.2161e-01,  4.6450e-01, -2.3086e-01, -4.7594e-02,\n",
       "           2.7328e-01],\n",
       "         [ 3.0097e-01,  7.0691e-03,  7.0798e-01,  8.4641e-02, -2.3800e-01,\n",
       "          -1.7997e-01, -2.7868e-01, -4.8705e-01, -3.1111e-01,  4.0821e-01,\n",
       "          -5.6711e-01, -2.5856e-01,  4.2090e-01, -2.1655e-01, -4.4848e-02,\n",
       "           3.0494e-01],\n",
       "         [ 2.8592e-01,  1.4706e-03,  7.0561e-01,  8.9645e-02, -2.1535e-01,\n",
       "          -1.9980e-01, -2.9348e-01, -4.6162e-01, -3.1614e-01,  3.9456e-01,\n",
       "          -5.7163e-01, -2.1537e-01,  4.0652e-01, -2.1966e-01, -5.1191e-02,\n",
       "           3.3522e-01]],\n",
       "\n",
       "        [[ 2.9734e-01, -6.1623e-02,  6.9303e-01,  6.6793e-02, -1.9005e-01,\n",
       "          -4.7542e-01, -2.8166e-01, -4.8734e-01, -2.4286e-01,  3.5322e-01,\n",
       "          -8.3095e-01, -1.7748e-01,  1.3556e-01, -1.8682e-01,  2.4667e-01,\n",
       "           3.5725e-01],\n",
       "         [ 3.7752e-01, -7.1688e-02,  7.7181e-01,  3.7964e-02, -2.4068e-01,\n",
       "          -2.8064e-01, -2.6938e-01, -4.3480e-01, -3.2432e-01,  4.0928e-01,\n",
       "          -5.6090e-01, -2.3311e-01,  2.2249e-01, -2.2088e-01,  2.5748e-01,\n",
       "           4.5712e-01],\n",
       "         [ 3.3063e-01, -5.4139e-02,  6.5539e-01,  2.5914e-02, -2.6252e-01,\n",
       "          -2.6584e-01, -2.5392e-01, -4.3429e-01, -4.1736e-01,  3.2758e-01,\n",
       "          -5.6865e-01, -1.7428e-01,  2.2785e-01, -2.1291e-01,  1.9579e-01,\n",
       "           4.3442e-01],\n",
       "         [ 2.0936e-01, -2.3066e-02,  6.7313e-01,  1.6257e-01, -2.3973e-01,\n",
       "          -2.1748e-01, -3.3098e-01, -3.9522e-01, -4.0605e-01,  2.4950e-01,\n",
       "          -5.6681e-01, -1.9780e-01,  2.2638e-01, -2.4887e-01,  1.4004e-01,\n",
       "           4.3449e-01],\n",
       "         [ 1.8909e-01, -5.5015e-02,  7.0626e-01,  1.5782e-01, -2.8488e-01,\n",
       "          -2.0010e-01, -3.6694e-01, -4.3001e-01, -4.3208e-01,  2.3845e-01,\n",
       "          -6.0995e-01, -1.7447e-01,  3.1350e-01, -2.2003e-01,  7.4468e-02,\n",
       "           4.3243e-01],\n",
       "         [ 1.9337e-01, -2.5589e-02,  6.6870e-01,  1.8738e-01, -2.4795e-01,\n",
       "          -1.7709e-01, -3.9890e-01, -4.6005e-01, -4.3200e-01,  2.5563e-01,\n",
       "          -6.2673e-01, -1.6339e-01,  3.0681e-01, -2.0168e-01,  9.4255e-02,\n",
       "           4.1230e-01],\n",
       "         [ 1.6136e-01, -3.4721e-02,  7.0169e-01,  1.8366e-01, -2.4852e-01,\n",
       "          -1.3969e-01, -4.0090e-01, -4.8320e-01, -3.8702e-01,  2.8004e-01,\n",
       "          -6.3717e-01, -1.9538e-01,  3.1599e-01, -2.8761e-01,  6.6624e-02,\n",
       "           3.9156e-01],\n",
       "         [ 1.6781e-01, -3.1931e-02,  7.1232e-01,  1.7877e-01, -2.5787e-01,\n",
       "          -1.3921e-01, -4.2390e-01, -4.9775e-01, -3.5101e-01,  2.7453e-01,\n",
       "          -6.0480e-01, -2.0186e-01,  3.1282e-01, -2.8842e-01,  7.6767e-02,\n",
       "           3.6014e-01]],\n",
       "\n",
       "        [[ 1.0498e-01, -2.0138e-01,  8.8925e-01,  2.2199e-01, -1.0608e-02,\n",
       "          -2.1692e-01, -2.6563e-01, -3.7924e-01, -4.4550e-01,  3.0077e-01,\n",
       "          -4.8922e-01, -3.2085e-01,  6.4975e-01, -2.8211e-01,  7.7013e-02,\n",
       "           4.5899e-01],\n",
       "         [ 2.3360e-01, -3.8447e-02,  8.7717e-01,  1.7620e-01, -2.4012e-01,\n",
       "          -1.4443e-01, -3.9346e-01, -5.4839e-01, -4.2414e-01,  3.5552e-01,\n",
       "          -5.9467e-01, -3.0860e-01,  6.6962e-01, -4.3349e-01, -8.3966e-02,\n",
       "           3.8643e-01],\n",
       "         [ 2.6452e-01,  4.9379e-02,  8.4017e-01,  1.0577e-01, -2.4231e-01,\n",
       "          -2.4462e-01, -4.0679e-01, -5.3279e-01, -3.7809e-01,  3.1679e-01,\n",
       "          -6.2967e-01, -1.8196e-01,  6.4540e-01, -3.3856e-01, -4.3221e-02,\n",
       "           3.0948e-01],\n",
       "         [ 3.0641e-01,  5.9203e-02,  8.4540e-01,  9.5645e-02, -2.9905e-01,\n",
       "          -2.3639e-01, -4.0454e-01, -5.6401e-01, -3.8266e-01,  3.3760e-01,\n",
       "          -6.1598e-01, -2.4806e-01,  6.1303e-01, -3.5601e-01, -1.7163e-02,\n",
       "           3.3185e-01],\n",
       "         [ 3.2437e-01,  6.5423e-02,  8.3744e-01,  6.3528e-02, -2.7782e-01,\n",
       "          -2.4671e-01, -3.6439e-01, -5.8134e-01, -3.6951e-01,  3.8218e-01,\n",
       "          -5.7903e-01, -2.3036e-01,  5.9263e-01, -3.4091e-01,  2.4179e-02,\n",
       "           3.1380e-01],\n",
       "         [ 2.8318e-01,  5.7355e-02,  8.1094e-01,  1.0373e-01, -2.5363e-01,\n",
       "          -2.7841e-01, -3.3396e-01, -5.4691e-01, -3.7221e-01,  3.5743e-01,\n",
       "          -5.6116e-01, -2.0054e-01,  5.7962e-01, -3.1533e-01,  2.2754e-02,\n",
       "           3.4760e-01],\n",
       "         [ 2.6016e-01,  6.0124e-02,  8.1852e-01,  9.8082e-02, -2.4954e-01,\n",
       "          -2.4407e-01, -3.6793e-01, -5.3750e-01, -3.2736e-01,  3.6117e-01,\n",
       "          -5.6731e-01, -1.9988e-01,  5.6522e-01, -3.3349e-01, -3.3921e-03,\n",
       "           2.8967e-01],\n",
       "         [ 2.4425e-01,  6.8103e-02,  7.8011e-01,  1.0613e-01, -2.2890e-01,\n",
       "          -2.5170e-01, -3.6045e-01, -5.1472e-01, -3.1395e-01,  3.3732e-01,\n",
       "          -5.6996e-01, -1.9576e-01,  4.8670e-01, -2.9460e-01,  1.4379e-02,\n",
       "           2.6075e-01]]], grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.rand(B,T,C)\n",
    "\n",
    "# single head self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B,T,16)\n",
    "q = query(x) # (B,T,16)\n",
    "wei = q @ k.transpose(-2, -1)  # (B,T,T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial-gpt-afn98zGi-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (main, Mar 30 2022, 15:42:06) [GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a146d1f8e5d910368f7d18ee396fe2a65c78aaaa29d3b4a89f6f9d99006ee40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
